{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbd14dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python311\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torch-geometric in c:\\python311\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\python311\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\python311\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: aiohttp in c:\\python311\\lib\\site-packages (from torch-geometric) (3.11.16)\n",
      "Requirement already satisfied: fsspec in c:\\python311\\lib\\site-packages (from torch-geometric) (2025.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\python311\\lib\\site-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in c:\\python311\\lib\\site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (1.19.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->torch-geometric) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->torch-geometric) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->torch-geometric) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torch-geometric numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2465e8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shapes - X: (362, 9, 1000, 4), y: (362, 9)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 143856000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 150\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded data with shapes - X: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, y: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# Convert to graph data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m graph_data = \u001b[43mcreate_graph_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(graph_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m graph samples\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# Split data\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mcreate_graph_data\u001b[39m\u001b[34m(X, y)\u001b[39m\n\u001b[32m     80\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m u != v:\n\u001b[32m     81\u001b[39m                     edge_index.append([u, v])\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     edge_index = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     graph_data_list.append(Data(\n\u001b[32m     86\u001b[39m         x=torch.tensor(node_features, dtype=torch.float),\n\u001b[32m     87\u001b[39m         edge_index=edge_index,\n\u001b[32m     88\u001b[39m         y=torch.tensor(y[i], dtype=torch.float)\n\u001b[32m     89\u001b[39m     ))\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m graph_data_list\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 143856000 bytes."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, SAGEConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Constants\n",
    "N, M, K, F = 362, 9, 1000, 4  # N samples, M algorithms, K boxes, F features\n",
    "class_labels = [\n",
    "    \"initial\", \"SCALE\", \"PFS\", \"PFS'\", \"FTA\",\n",
    "    \"VPSC\", \"PRISM\", \"GTREE\", \"RWordle-L\"\n",
    "]\n",
    "\n",
    "# ----------------- Data Loading and Processing -----------------\n",
    "def load_and_process_data(json_path, csv_path):\n",
    "    # Load data\n",
    "    with open(json_path, \"r\") as f:\n",
    "        sets_data = json.load(f)\n",
    "    scores_df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Initialize tensors\n",
    "    X = np.zeros((N, M, K, F), dtype=np.float32)\n",
    "    y = np.zeros((N, M), dtype=np.float32)\n",
    "    \n",
    "    # Create filename to index mapping\n",
    "    filename_to_idx = {entry['base_name']: idx for idx, entry in enumerate(sets_data)}\n",
    "    \n",
    "    # Process each entry\n",
    "    for entry in sets_data:\n",
    "        base_name = entry['base_name']\n",
    "        idx = filename_to_idx.get(base_name, -1)\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        \n",
    "        boxes = entry['boxes']  # This is already a list of boxes per algorithm\n",
    "        file_scores = scores_df[scores_df['filename'] == base_name]\n",
    "        \n",
    "        for algo_idx, algo in enumerate(class_labels):\n",
    "            # Get score\n",
    "            score_row = file_scores[file_scores['algorithm'] == algo]\n",
    "            if not score_row.empty:\n",
    "                y[idx, algo_idx] = score_row['score'].values[0]\n",
    "            \n",
    "            # Get boxes - handle cases where boxes might be missing\n",
    "            if algo_idx < len(boxes):\n",
    "                # Check if current algorithm's boxes exist\n",
    "                algo_boxes = boxes[algo_idx] if isinstance(boxes[algo_idx], list) else []\n",
    "                \n",
    "                # Handle single box case (convert to list of boxes)\n",
    "                if algo_boxes and isinstance(algo_boxes[0], (int, float)):\n",
    "                    algo_boxes = [algo_boxes]  # Make it a list containing one box\n",
    "                \n",
    "                # Store boxes\n",
    "                for box_idx, box in enumerate(algo_boxes[:K]):\n",
    "                    if isinstance(box, list) and len(box) == F:\n",
    "                        X[idx, algo_idx, box_idx] = box\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Convert to PyG Data format\n",
    "def create_graph_data(X, y):\n",
    "    graph_data_list = []\n",
    "    for i in range(X.shape[0]):\n",
    "        # Node features (M*K, F)\n",
    "        node_features = X[i].reshape(-1, F)\n",
    "        \n",
    "        # Create edges (fully connected within each algorithm)\n",
    "        edge_index = []\n",
    "        for algo_idx in range(M):\n",
    "            start = algo_idx * K\n",
    "            end = start + K\n",
    "            # Fully connect boxes within same algorithm\n",
    "            for u in range(start, end):\n",
    "                for v in range(start, end):\n",
    "                    if u != v:\n",
    "                        edge_index.append([u, v])\n",
    "        \n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        \n",
    "        graph_data_list.append(Data(\n",
    "            x=torch.tensor(node_features, dtype=torch.float),\n",
    "            edge_index=edge_index,\n",
    "            y=torch.tensor(y[i], dtype=torch.float)\n",
    "        ))\n",
    "    return graph_data_list\n",
    "\n",
    "# ----------------- GNN Models -----------------\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, node_dim=F, hidden_dim=64, output_dim=M, heads=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(node_dim, hidden_dim, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_dim*heads, hidden_dim, heads=1)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.elu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch=torch.zeros(data.num_nodes, dtype=torch.long, device=x.device))\n",
    "        return self.fc(x)\n",
    "\n",
    "class SAGEModel(nn.Module):\n",
    "    def __init__(self, node_dim=F, hidden_dim=64, output_dim=M):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(node_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.elu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch=torch.zeros(data.num_nodes, dtype=torch.long, device=x.device))\n",
    "        return self.fc(x)\n",
    "\n",
    "# ----------------- Training -----------------\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def test(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data)\n",
    "            total_loss += criterion(out, data.y).item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# ----------------- Main -----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and process data\n",
    "    X, y = load_and_process_data(\"merge.json\", \"scoresB2.csv\")\n",
    "    print(f\"Loaded data with shapes - X: {X.shape}, y: {y.shape}\")\n",
    "    \n",
    "    # Convert to graph data\n",
    "    graph_data = create_graph_data(X, y)\n",
    "    print(f\"Created {len(graph_data)} graph samples\")\n",
    "    \n",
    "    # Split data\n",
    "    train_data, test_data = train_test_split(graph_data, test_size=0.2, random_state=42)\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "    \n",
    "    # Initialize models\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    gat = GATModel().to(device)\n",
    "    sage = SAGEModel().to(device)\n",
    "    \n",
    "    # Training setup\n",
    "    criterion = nn.MSELoss()\n",
    "    gat_optim = optim.Adam(gat.parameters(), lr=0.001)\n",
    "    sage_optim = optim.Adam(sage.parameters(), lr=0.001)\n",
    "    \n",
    "    # Train and compare\n",
    "    print(\"\\nTraining GAT Model:\")\n",
    "    for epoch in range(100):\n",
    "        loss = train(gat, train_loader, gat_optim, criterion)\n",
    "        test_loss = test(gat, test_loader, criterion)\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1:03d}, Train Loss: {loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    print(\"\\nTraining GraphSAGE Model:\")\n",
    "    for epoch in range(100):\n",
    "        loss = train(sage, train_loader, sage_optim, criterion)\n",
    "        test_loss = test(sage, test_loader, criterion)\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1:03d}, Train Loss: {loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    # Final comparison\n",
    "    gat_test_loss = test(gat, test_loader, criterion)\n",
    "    sage_test_loss = test(sage, test_loader, criterion)\n",
    "    print(f\"\\nFinal Comparison:\")\n",
    "    print(f\"GAT Test MSE: {gat_test_loss:.4f}\")\n",
    "    print(f\"GraphSAGE Test MSE: {sage_test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
