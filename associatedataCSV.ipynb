{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa70fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully restructured JSON and saved to rescruction/restructured_layouts1.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def restructure_json(input_file, output_file):\n",
    "    # Define the fixed order of algorithms\n",
    "    algorithm_order = [\"initial\", \"SCALE\", \"PFS\", \"PFS'\", \"FTA\", \"VPSC\", \"PRISM\", \"GTREE\", \"RWordle-L\"]\n",
    "    \n",
    "    # Load the original JSON data\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Restructure each entry\n",
    "    restructured_data = []\n",
    "    for entry in data:\n",
    "        new_entry = {\n",
    "            \"base_name\": entry[\"base_name\"],\n",
    "            \"layouts\": []\n",
    "        }\n",
    "        \n",
    "        # Add layouts in the specified order\n",
    "        for algo in algorithm_order:\n",
    "            if algo in entry:\n",
    "                new_entry[\"layouts\"].append(entry[algo])\n",
    "            else:\n",
    "                # If algorithm is missing, add empty list\n",
    "                new_entry[\"layouts\"].append([])\n",
    "        \n",
    "        restructured_data.append(new_entry)\n",
    "    \n",
    "    # Save the restructured data\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(restructured_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Successfully restructured JSON and saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_json = \"final_merged_with_initial.json\"\n",
    "output_json = \"rescruction/restructured_layouts1.json\"\n",
    "restructure_json(input_json, output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4100949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading data files...\n",
      "Loaded CSV with 6720 rows\n",
      "\n",
      "🔎 Verifying filename matching...\n",
      "Common files: 362\n",
      "\n",
      "🛠 Creating merge.json...\n",
      "\n",
      "💯 Creating scores.csv...\n",
      "\n",
      "📊 Score Summary:\n",
      "Total entries: 3258\n",
      "Non-zero scores: 2896\n",
      "Score distribution by algorithm:\n",
      "           count      mean       std    min    25%    50%      75%    max\n",
      "algorithm                                                                \n",
      "FTA        362.0  0.703569  0.146990  0.081  0.661  0.789  0.81300  0.813\n",
      "GTREE      362.0  0.674914  0.117943  0.393  0.563  0.697  0.79475  0.813\n",
      "PFS        362.0  0.668561  0.167271  0.294  0.537  0.758  0.81300  0.813\n",
      "PFS'       362.0  0.714834  0.116863  0.408  0.619  0.777  0.81300  0.813\n",
      "PRISM      362.0  0.684475  0.121630  0.374  0.575  0.716  0.80625  0.813\n",
      "RWordle-L  362.0  0.749204  0.064635  0.410  0.716  0.767  0.81300  0.813\n",
      "SCALE      362.0  0.680514  0.121549  0.481  0.547  0.704  0.81300  0.813\n",
      "VPSC       362.0  0.740994  0.106512  0.171  0.716  0.799  0.81300  0.813\n",
      "initial    362.0  0.000000  0.000000  0.000  0.000  0.000  0.00000  0.000\n",
      "\n",
      "✅ Done! Files created in restruction\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "INPUT_JSON = \"final_merged_with_initial.json\"\n",
    "INPUT_CSV = \"output_scoresBYAZENoP.csv\"\n",
    "OUTPUT_DIR = \"restruction\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Algorithm name mappings (JSON name : CSV name)\n",
    "ALGORITHM_MAPPING = {\n",
    "    \"initial\": \"initial\",\n",
    "    \"SCALE\": \"scale\",\n",
    "    \"PFS\": \"pfs\",\n",
    "    \"PFS'\": \"PFS'\",\n",
    "    \"FTA\": \"fta\",\n",
    "    \"VPSC\": \"vpsc\",\n",
    "    \"PRISM\": \"prism\",\n",
    "    \"GTREE\": \"gtree\",\n",
    "    \"RWordle-L\": \"RWordle-L\"\n",
    "}\n",
    "\n",
    "# Load data files\n",
    "print(\"🔍 Loading data files...\")\n",
    "with open(INPUT_JSON, \"r\") as f:\n",
    "    layout_data = json.load(f)\n",
    "\n",
    "try:\n",
    "    gqs_scores = pd.read_csv(INPUT_CSV)\n",
    "    print(f\"Loaded CSV with {len(gqs_scores)} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 1. Verify filename matching\n",
    "print(\"\\n🔎 Verifying filename matching...\")\n",
    "json_files = {entry[\"base_name\"] for entry in layout_data}\n",
    "csv_files = set(gqs_scores[\"filename\"].unique())\n",
    "\n",
    "common_files = json_files & csv_files\n",
    "print(f\"Common files: {len(common_files)}\")\n",
    "\n",
    "# 2. Create merge.json\n",
    "print(\"\\n🛠 Creating merge.json...\")\n",
    "output_data = []\n",
    "algorithms = list(ALGORITHM_MAPPING.keys())  # Use JSON algorithm names\n",
    "\n",
    "for entry in layout_data:\n",
    "    graph_entry = {\n",
    "        \"base_name\": entry[\"base_name\"],\n",
    "        \"boxes\": []\n",
    "    }\n",
    "    \n",
    "    for algo in algorithms:\n",
    "        if algo in entry:\n",
    "            graph_entry[\"boxes\"].extend(entry[algo])\n",
    "    \n",
    "    output_data.append(graph_entry)\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/merge.json\", \"w\") as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "# 3. Create scores.csv with proper score matching\n",
    "print(\"\\n💯 Creating scores.csv...\")\n",
    "scores_data = []\n",
    "\n",
    "for entry in layout_data:\n",
    "    base_name = entry[\"base_name\"]\n",
    "    \n",
    "    for json_algo, csv_algo in ALGORITHM_MAPPING.items():\n",
    "        if json_algo == \"initial\":\n",
    "            score = 0.0\n",
    "        else:\n",
    "            # Check for match in CSV (case insensitive)\n",
    "            match = gqs_scores[\n",
    "                (gqs_scores[\"filename\"].str.lower() == base_name.lower()) & \n",
    "                (gqs_scores[\"algorithm\"].str.lower() == csv_algo.lower())\n",
    "            ]\n",
    "            \n",
    "            if not match.empty:\n",
    "                score = match[\"score\"].values[0]\n",
    "            else:\n",
    "                score = 0.0\n",
    "        \n",
    "        scores_data.append({\n",
    "            \"filename\": base_name,\n",
    "            \"algorithm\": json_algo,  # Use JSON algorithm name in output\n",
    "            \"score\": float(score)\n",
    "        })\n",
    "\n",
    "# Save scores\n",
    "scores_df = pd.DataFrame(scores_data)\n",
    "scores_df.to_csv(f\"{OUTPUT_DIR}/scoresB2.csv\", index=False)\n",
    "\n",
    "# Verify results\n",
    "print(\"\\n📊 Score Summary:\")\n",
    "print(f\"Total entries: {len(scores_data)}\")\n",
    "print(f\"Non-zero scores: {len(scores_df[scores_df['score'] > 0])}\")\n",
    "print(\"Score distribution by algorithm:\")\n",
    "print(scores_df.groupby('algorithm')['score'].describe())\n",
    "\n",
    "print(\"\\n✅ Done! Files created in\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058e7c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 File Comparison Results:\n",
      "Total files in CSV: 840\n",
      "Total files in JSON: 362\n",
      "Files present in both: 362\n",
      "\n",
      "🚨 Files only in CSV:\n",
      "- pa_1000_1\n",
      "- pa_1000_10\n",
      "- pa_1000_11\n",
      "- pa_1000_12\n",
      "- pa_1000_13\n",
      "- pa_1000_14\n",
      "- pa_1000_15\n",
      "- pa_1000_16\n",
      "- pa_1000_17\n",
      "- pa_1000_18\n",
      "- pa_1000_19\n",
      "- pa_1000_2\n",
      "- pa_1000_20\n",
      "- pa_1000_21\n",
      "- pa_1000_22\n",
      "- pa_1000_23\n",
      "- pa_1000_24\n",
      "- pa_1000_25\n",
      "- pa_1000_26\n",
      "- pa_1000_27\n",
      "- pa_1000_28\n",
      "- pa_1000_29\n",
      "- pa_1000_3\n",
      "- pa_1000_30\n",
      "- pa_1000_4\n",
      "- pa_1000_5\n",
      "- pa_1000_6\n",
      "- pa_1000_7\n",
      "- pa_1000_8\n",
      "- pa_1000_9\n",
      "- pa_100_1\n",
      "- pa_100_10\n",
      "- pa_100_11\n",
      "- pa_100_12\n",
      "- pa_100_13\n",
      "- pa_100_14\n",
      "- pa_100_15\n",
      "- pa_100_16\n",
      "- pa_100_17\n",
      "- pa_100_18\n",
      "- pa_100_19\n",
      "- pa_100_2\n",
      "- pa_100_20\n",
      "- pa_100_21\n",
      "- pa_100_22\n",
      "- pa_100_23\n",
      "- pa_100_24\n",
      "- pa_100_25\n",
      "- pa_100_26\n",
      "- pa_100_27\n",
      "- pa_100_28\n",
      "- pa_100_29\n",
      "- pa_100_3\n",
      "- pa_100_30\n",
      "- pa_100_4\n",
      "- pa_100_5\n",
      "- pa_100_6\n",
      "- pa_100_7\n",
      "- pa_100_8\n",
      "- pa_100_9\n",
      "- pa_200_1\n",
      "- pa_200_10\n",
      "- pa_200_11\n",
      "- pa_200_12\n",
      "- pa_200_13\n",
      "- pa_200_14\n",
      "- pa_200_15\n",
      "- pa_200_16\n",
      "- pa_200_17\n",
      "- pa_200_18\n",
      "- pa_200_19\n",
      "- pa_200_2\n",
      "- pa_200_20\n",
      "- pa_200_21\n",
      "- pa_200_22\n",
      "- pa_200_23\n",
      "- pa_200_24\n",
      "- pa_200_25\n",
      "- pa_200_26\n",
      "- pa_200_27\n",
      "- pa_200_28\n",
      "- pa_200_29\n",
      "- pa_200_3\n",
      "- pa_200_30\n",
      "- pa_200_4\n",
      "- pa_200_5\n",
      "- pa_200_6\n",
      "- pa_200_7\n",
      "- pa_200_8\n",
      "- pa_200_9\n",
      "- pa_500_1\n",
      "- pa_500_10\n",
      "- pa_500_11\n",
      "- pa_500_12\n",
      "- pa_500_13\n",
      "- pa_500_14\n",
      "- pa_500_15\n",
      "- pa_500_16\n",
      "- pa_500_17\n",
      "- pa_500_18\n",
      "- pa_500_19\n",
      "- pa_500_2\n",
      "- pa_500_20\n",
      "- pa_500_21\n",
      "- pa_500_22\n",
      "- pa_500_23\n",
      "- pa_500_24\n",
      "- pa_500_25\n",
      "- pa_500_26\n",
      "- pa_500_27\n",
      "- pa_500_28\n",
      "- pa_500_29\n",
      "- pa_500_3\n",
      "- pa_500_30\n",
      "- pa_500_4\n",
      "- pa_500_5\n",
      "- pa_500_6\n",
      "- pa_500_7\n",
      "- random_1000_1\n",
      "- random_1000_10\n",
      "- random_1000_11\n",
      "- random_1000_12\n",
      "- random_1000_13\n",
      "- random_1000_14\n",
      "- random_1000_15\n",
      "- random_1000_16\n",
      "- random_1000_17\n",
      "- random_1000_18\n",
      "- random_1000_19\n",
      "- random_1000_2\n",
      "- random_1000_20\n",
      "- random_1000_21\n",
      "- random_1000_22\n",
      "- random_1000_23\n",
      "- random_1000_24\n",
      "- random_1000_25\n",
      "- random_1000_26\n",
      "- random_1000_27\n",
      "- random_1000_28\n",
      "- random_1000_29\n",
      "- random_1000_3\n",
      "- random_1000_30\n",
      "- random_1000_4\n",
      "- random_1000_5\n",
      "- random_1000_6\n",
      "- random_1000_7\n",
      "- random_1000_8\n",
      "- random_1000_9\n",
      "- random_100_1\n",
      "- random_100_10\n",
      "- random_100_11\n",
      "- random_100_12\n",
      "- random_100_13\n",
      "- random_100_14\n",
      "- random_100_15\n",
      "- random_100_16\n",
      "- random_100_17\n",
      "- random_100_18\n",
      "- random_100_19\n",
      "- random_100_2\n",
      "- random_100_20\n",
      "- random_100_21\n",
      "- random_100_22\n",
      "- random_100_23\n",
      "- random_100_24\n",
      "- random_100_25\n",
      "- random_100_26\n",
      "- random_100_27\n",
      "- random_100_28\n",
      "- random_100_29\n",
      "- random_100_3\n",
      "- random_100_30\n",
      "- random_100_4\n",
      "- random_100_5\n",
      "- random_100_6\n",
      "- random_100_7\n",
      "- random_100_8\n",
      "- random_100_9\n",
      "- random_200_1\n",
      "- random_200_10\n",
      "- random_200_11\n",
      "- random_200_12\n",
      "- random_200_13\n",
      "- random_200_14\n",
      "- random_200_15\n",
      "- random_200_16\n",
      "- random_200_17\n",
      "- random_200_18\n",
      "- random_200_19\n",
      "- random_200_2\n",
      "- random_200_20\n",
      "- random_200_21\n",
      "- random_200_22\n",
      "- random_200_23\n",
      "- random_200_24\n",
      "- random_200_25\n",
      "- random_200_26\n",
      "- random_200_27\n",
      "- random_200_28\n",
      "- random_200_29\n",
      "- random_200_3\n",
      "- random_200_30\n",
      "- random_200_4\n",
      "- random_200_5\n",
      "- random_200_6\n",
      "- random_200_7\n",
      "- random_200_8\n",
      "- random_200_9\n",
      "- random_500_1\n",
      "- random_500_10\n",
      "- random_500_11\n",
      "- random_500_12\n",
      "- random_500_13\n",
      "- random_500_14\n",
      "- random_500_15\n",
      "- random_500_16\n",
      "- random_500_17\n",
      "- random_500_18\n",
      "- random_500_19\n",
      "- random_500_2\n",
      "- random_500_20\n",
      "- random_500_21\n",
      "- random_500_22\n",
      "- random_500_23\n",
      "- random_500_24\n",
      "- random_500_25\n",
      "- random_500_26\n",
      "- random_500_27\n",
      "- random_500_28\n",
      "- random_500_29\n",
      "- random_500_3\n",
      "- random_500_30\n",
      "- random_500_4\n",
      "- random_500_5\n",
      "- random_500_6\n",
      "- random_500_7\n",
      "- random_500_8\n",
      "- random_500_9\n",
      "- tree_1000_1\n",
      "- tree_1000_10\n",
      "- tree_1000_11\n",
      "- tree_1000_12\n",
      "- tree_1000_13\n",
      "- tree_1000_14\n",
      "- tree_1000_15\n",
      "- tree_1000_16\n",
      "- tree_1000_17\n",
      "- tree_1000_18\n",
      "- tree_1000_19\n",
      "- tree_1000_2\n",
      "- tree_1000_20\n",
      "- tree_1000_21\n",
      "- tree_1000_22\n",
      "- tree_1000_23\n",
      "- tree_1000_24\n",
      "- tree_1000_25\n",
      "- tree_1000_26\n",
      "- tree_1000_27\n",
      "- tree_1000_28\n",
      "- tree_1000_29\n",
      "- tree_1000_3\n",
      "- tree_1000_30\n",
      "- tree_1000_4\n",
      "- tree_1000_5\n",
      "- tree_1000_6\n",
      "- tree_1000_7\n",
      "- tree_1000_8\n",
      "- tree_1000_9\n",
      "- tree_100_1\n",
      "- tree_100_10\n",
      "- tree_100_11\n",
      "- tree_100_12\n",
      "- tree_100_13\n",
      "- tree_100_14\n",
      "- tree_100_15\n",
      "- tree_100_16\n",
      "- tree_100_17\n",
      "- tree_100_18\n",
      "- tree_100_19\n",
      "- tree_100_2\n",
      "- tree_100_20\n",
      "- tree_100_21\n",
      "- tree_100_22\n",
      "- tree_100_23\n",
      "- tree_100_24\n",
      "- tree_100_25\n",
      "- tree_100_26\n",
      "- tree_100_27\n",
      "- tree_100_28\n",
      "- tree_100_29\n",
      "- tree_100_3\n",
      "- tree_100_30\n",
      "- tree_100_4\n",
      "- tree_100_5\n",
      "- tree_100_6\n",
      "- tree_100_7\n",
      "- tree_100_8\n",
      "- tree_100_9\n",
      "- tree_200_1\n",
      "- tree_200_10\n",
      "- tree_200_11\n",
      "- tree_200_12\n",
      "- tree_200_13\n",
      "- tree_200_14\n",
      "- tree_200_15\n",
      "- tree_200_16\n",
      "- tree_200_17\n",
      "- tree_200_18\n",
      "- tree_200_19\n",
      "- tree_200_2\n",
      "- tree_200_20\n",
      "- tree_200_21\n",
      "- tree_200_22\n",
      "- tree_200_23\n",
      "- tree_200_24\n",
      "- tree_200_25\n",
      "- tree_200_26\n",
      "- tree_200_27\n",
      "- tree_200_28\n",
      "- tree_200_29\n",
      "- tree_200_3\n",
      "- tree_200_30\n",
      "- tree_200_4\n",
      "- tree_200_5\n",
      "- tree_200_6\n",
      "- tree_200_7\n",
      "- tree_200_8\n",
      "- tree_200_9\n",
      "- tree_500_1\n",
      "- tree_500_10\n",
      "- tree_500_11\n",
      "- tree_500_12\n",
      "- tree_500_13\n",
      "- tree_500_14\n",
      "- tree_500_15\n",
      "- tree_500_16\n",
      "- tree_500_17\n",
      "- tree_500_18\n",
      "- tree_500_19\n",
      "- tree_500_2\n",
      "- tree_500_20\n",
      "- tree_500_21\n",
      "- tree_500_22\n",
      "- tree_500_23\n",
      "- tree_500_24\n",
      "- tree_500_25\n",
      "- tree_500_26\n",
      "- tree_500_27\n",
      "- tree_500_28\n",
      "- tree_500_29\n",
      "- tree_500_3\n",
      "- tree_500_30\n",
      "- tree_500_4\n",
      "- tree_500_5\n",
      "- tree_500_6\n",
      "- tree_500_7\n",
      "- tree_500_8\n",
      "- tree_500_9\n",
      "- ws_1000_1\n",
      "- ws_1000_10\n",
      "- ws_1000_11\n",
      "- ws_1000_12\n",
      "- ws_1000_13\n",
      "- ws_1000_14\n",
      "- ws_1000_15\n",
      "- ws_1000_16\n",
      "- ws_1000_17\n",
      "- ws_1000_18\n",
      "- ws_1000_19\n",
      "- ws_1000_2\n",
      "- ws_1000_20\n",
      "- ws_1000_21\n",
      "- ws_1000_22\n",
      "- ws_1000_23\n",
      "- ws_1000_24\n",
      "- ws_1000_25\n",
      "- ws_1000_26\n",
      "- ws_1000_27\n",
      "- ws_1000_28\n",
      "- ws_1000_29\n",
      "- ws_1000_3\n",
      "- ws_1000_30\n",
      "- ws_1000_4\n",
      "- ws_1000_5\n",
      "- ws_1000_6\n",
      "- ws_1000_7\n",
      "- ws_1000_8\n",
      "- ws_1000_9\n",
      "- ws_100_1\n",
      "- ws_100_10\n",
      "- ws_100_11\n",
      "- ws_100_12\n",
      "- ws_100_13\n",
      "- ws_100_14\n",
      "- ws_100_15\n",
      "- ws_100_16\n",
      "- ws_100_17\n",
      "- ws_100_18\n",
      "- ws_100_19\n",
      "- ws_100_2\n",
      "- ws_100_20\n",
      "- ws_100_21\n",
      "- ws_100_22\n",
      "- ws_100_23\n",
      "- ws_100_24\n",
      "- ws_100_25\n",
      "- ws_100_26\n",
      "- ws_100_27\n",
      "- ws_100_28\n",
      "- ws_100_29\n",
      "- ws_100_3\n",
      "- ws_100_30\n",
      "- ws_100_4\n",
      "- ws_100_5\n",
      "- ws_100_6\n",
      "- ws_100_7\n",
      "- ws_100_8\n",
      "- ws_100_9\n",
      "- ws_200_1\n",
      "- ws_200_10\n",
      "- ws_200_11\n",
      "- ws_200_12\n",
      "- ws_200_13\n",
      "- ws_200_14\n",
      "- ws_200_15\n",
      "- ws_200_16\n",
      "- ws_200_17\n",
      "- ws_200_18\n",
      "- ws_200_19\n",
      "- ws_200_2\n",
      "- ws_200_20\n",
      "- ws_200_21\n",
      "- ws_200_22\n",
      "- ws_200_23\n",
      "- ws_200_24\n",
      "- ws_200_25\n",
      "- ws_200_26\n",
      "- ws_200_27\n",
      "- ws_200_28\n",
      "- ws_200_29\n",
      "- ws_200_3\n",
      "- ws_200_30\n",
      "- ws_200_4\n",
      "- ws_200_5\n",
      "- ws_200_6\n",
      "- ws_200_7\n",
      "- ws_200_8\n",
      "- ws_200_9\n",
      "- ws_500_1\n",
      "- ws_500_10\n",
      "- ws_500_11\n",
      "- ws_500_12\n",
      "- ws_500_13\n",
      "- ws_500_14\n",
      "- ws_500_15\n",
      "- ws_500_16\n",
      "- ws_500_17\n",
      "- ws_500_18\n",
      "- ws_500_19\n",
      "- ws_500_2\n",
      "- ws_500_20\n",
      "- ws_500_21\n",
      "- ws_500_22\n",
      "- ws_500_23\n",
      "- ws_500_24\n",
      "- ws_500_25\n",
      "- ws_500_26\n",
      "- ws_500_27\n",
      "- ws_500_28\n",
      "- ws_500_29\n",
      "- ws_500_3\n",
      "- ws_500_30\n",
      "- ws_500_4\n",
      "- ws_500_5\n",
      "- ws_500_6\n",
      "- ws_500_7\n",
      "- ws_500_8\n",
      "- ws_500_9\n",
      "\n",
      "✅ Comparison complete. Common files saved to 'common_files.txt'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def compare_csv_json(csv_path, json_path):\n",
    "    # Load the CSV data\n",
    "    csv_data = pd.read_csv(csv_path)\n",
    "    csv_files = set(csv_data['filename'].unique())\n",
    "    \n",
    "    # Load the JSON data\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    json_files = set(entry['base_name'] for entry in json_data)\n",
    "    \n",
    "    # Find matches and mismatches\n",
    "    files_in_both = csv_files & json_files\n",
    "    files_only_in_csv = csv_files - json_files\n",
    "    files_only_in_json = json_files - csv_files\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n📋 File Comparison Results:\")\n",
    "    print(f\"Total files in CSV: {len(csv_files)}\")\n",
    "    print(f\"Total files in JSON: {len(json_files)}\")\n",
    "    print(f\"Files present in both: {len(files_in_both)}\")\n",
    "    \n",
    "    if files_only_in_csv:\n",
    "        print(\"\\n🚨 Files only in CSV:\")\n",
    "        for file in sorted(files_only_in_csv):\n",
    "            print(f\"- {file}\")\n",
    "    \n",
    "    if files_only_in_json:\n",
    "        print(\"\\n🚨 Files only in JSON:\")\n",
    "        for file in sorted(files_only_in_json):\n",
    "            print(f\"- {file}\")\n",
    "    \n",
    "    # Return the results\n",
    "    return {\n",
    "        'common_files': sorted(files_in_both),\n",
    "        'csv_only': sorted(files_only_in_csv),\n",
    "        'json_only': sorted(files_only_in_json)\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"gqs_scores_per_algorithm.csv\"  # Replace with your CSV path\n",
    "    json_path = \"final_merged_with_initial.json\"  # Replace with your JSON path\n",
    "    \n",
    "    results = compare_csv_json(csv_path, json_path)\n",
    "    \n",
    "    # Save common files to a text file\n",
    "    with open(\"common_files.txt\", \"w\") as f:\n",
    "        f.write(\"Files present in both CSV and JSON:\\n\")\n",
    "        f.write(\"\\n\".join(results['common_files']))\n",
    "    \n",
    "    print(\"\\n✅ Comparison complete. Common files saved to 'common_files.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
