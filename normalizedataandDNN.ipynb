{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330ce29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tensor shape: (362, 9, 1000, 4)\n",
      "Y_tensor shape: (362, 9)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Constants\n",
    "N, M, K, F = 362, 9, 1000, 4\n",
    "class_labels = [\n",
    "    \"initial\", \"SCALE\", \"PFS\", \"PFS'\", \"FTA\",\n",
    "    \"VPSC\", \"PRISM\", \"GTREE\", \"RWordle-L\"\n",
    "]\n",
    "\n",
    "# ---------------- Load Data ----------------\n",
    "with open(\"merge.json\", \"r\") as f:\n",
    "    sets_data = json.load(f)\n",
    "\n",
    "scores_df = pd.read_csv(\"scores.csv\")\n",
    "\n",
    "# Initialize tensors\n",
    "X_tensor = np.zeros((N, M, K, F), dtype=np.float32)\n",
    "Y_tensor = np.zeros((N, M), dtype=np.float32)\n",
    "\n",
    "# ---------------- Data Processing Functions ----------------\n",
    "def is_valid_box(box):\n",
    "    \"\"\"Check if the box has the correct format [x, y, width, height]\"\"\"\n",
    "    return isinstance(box, list) and len(box) == F and all(isinstance(x, (int, float)) for x in box)\n",
    "\n",
    "def normalize_box(box):\n",
    "    \"\"\"Normalize box coordinates to [0, 1] range\"\"\"\n",
    "    # Adjust these denominators based on your actual data range\n",
    "    return [\n",
    "        box[0] / 100.0,    # x position\n",
    "        box[1] / 100.0,    # y position\n",
    "        box[2] / 50.0,     # width\n",
    "        box[3] / 50.0      # height\n",
    "    ]\n",
    "\n",
    "def process_data(sets_data, scores_df):\n",
    "    \"\"\"Process and normalize all data into tensors\"\"\"\n",
    "    # Create mapping from filename to index\n",
    "    filename_to_idx = {entry['base_name']: idx for idx, entry in enumerate(sets_data)}\n",
    "    \n",
    "    # Process each entry in the dataset\n",
    "    for entry in sets_data:\n",
    "        base_name = entry['base_name']\n",
    "        idx = filename_to_idx.get(base_name, -1)\n",
    "        if idx == -1:\n",
    "            continue  # Skip if base_name not found\n",
    "        \n",
    "        boxes = entry.get('boxes', [])\n",
    "        \n",
    "        # Get scores for this file\n",
    "        file_scores = scores_df[scores_df['filename'] == base_name]\n",
    "        \n",
    "        # Process each algorithm's boxes and scores\n",
    "        for algo_idx, algo in enumerate(class_labels):\n",
    "            # Get score for this algorithm\n",
    "            score_row = file_scores[file_scores['algorithm'] == algo]\n",
    "            if not score_row.empty:\n",
    "                Y_tensor[idx, algo_idx] = score_row['score'].values[0]\n",
    "            \n",
    "            # Get boxes for this algorithm - handle cases where boxes might not match class_labels\n",
    "            if isinstance(boxes, list) and algo_idx < len(boxes):\n",
    "                algo_boxes = boxes[algo_idx]\n",
    "                \n",
    "                # Handle case where algo_boxes might be a single box or list of boxes\n",
    "                if is_valid_box(algo_boxes):\n",
    "                    # Single box case\n",
    "                    X_tensor[idx, algo_idx, 0] = normalize_box(algo_boxes)\n",
    "                elif isinstance(algo_boxes, list):\n",
    "                    # Multiple boxes case\n",
    "                    for box_idx, box in enumerate(algo_boxes[:K]):  # Truncate to K boxes\n",
    "                        if is_valid_box(box):\n",
    "                            X_tensor[idx, algo_idx, box_idx] = normalize_box(box)\n",
    "    \n",
    "    return X_tensor, Y_tensor\n",
    "\n",
    "# ---------------- Main Processing ----------------\n",
    "try:\n",
    "    X_tensor, Y_tensor = process_data(sets_data, scores_df)\n",
    "    print(f\"X_tensor shape: {X_tensor.shape}\")  # Should be (362, 9, 1000, 4)\n",
    "    print(f\"Y_tensor shape: {Y_tensor.shape}\")  # Should be (362, 9)\n",
    "    \n",
    "    # Optional: Save tensors\n",
    "    np.save(\"X_tensor.npy\", X_tensor)\n",
    "    np.save(\"Y_tensor.npy\", Y_tensor)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4fa6a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.9578 - Test Loss: 1.0406\n",
      "Epoch 2/20 - Train Loss: 0.5229 - Test Loss: 0.0845\n",
      "Epoch 3/20 - Train Loss: 0.3238 - Test Loss: 0.0982\n",
      "Epoch 4/20 - Train Loss: 0.0916 - Test Loss: 0.0852\n",
      "Epoch 5/20 - Train Loss: 0.0877 - Test Loss: 0.0843\n",
      "Epoch 6/20 - Train Loss: 0.0848 - Test Loss: 0.0861\n",
      "Epoch 7/20 - Train Loss: 0.0850 - Test Loss: 0.0882\n",
      "Epoch 8/20 - Train Loss: 0.0861 - Test Loss: 0.0870\n",
      "Epoch 9/20 - Train Loss: 0.0863 - Test Loss: 0.0914\n",
      "Epoch 10/20 - Train Loss: 0.0892 - Test Loss: 0.0876\n",
      "Epoch 11/20 - Train Loss: 0.0854 - Test Loss: 0.0922\n",
      "Epoch 12/20 - Train Loss: 0.0861 - Test Loss: 0.0836\n",
      "Epoch 13/20 - Train Loss: 0.0833 - Test Loss: 0.0830\n",
      "Epoch 14/20 - Train Loss: 0.0831 - Test Loss: 0.0825\n",
      "Epoch 15/20 - Train Loss: 0.0829 - Test Loss: 0.0861\n",
      "Epoch 16/20 - Train Loss: 0.0841 - Test Loss: 0.0824\n",
      "Epoch 17/20 - Train Loss: 0.0828 - Test Loss: 0.0826\n",
      "Epoch 18/20 - Train Loss: 0.0825 - Test Loss: 0.0819\n",
      "Epoch 19/20 - Train Loss: 0.0822 - Test Loss: 0.0811\n",
      "Epoch 20/20 - Train Loss: 0.0817 - Test Loss: 0.0814\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the saved tensors\n",
    "X_tensor = np.load(\"X_tensor.npy\")  # Shape: (N, M, K, F)\n",
    "Y_tensor = np.load(\"Y_tensor.npy\")  # Shape: (N, M)\n",
    "\n",
    "# Dataset Class\n",
    "class BoxDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, Y_tensor, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = BoxDataset(X_train, y_train)\n",
    "test_dataset = BoxDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Fixed Neural Network Architecture with proper reshaping\n",
    "class BoxPredictor(nn.Module):\n",
    "    def __init__(self, M, K, F):\n",
    "        super(BoxPredictor, self).__init__()\n",
    "        self.M = M  # Number of algorithms (9)\n",
    "        self.K = K  # Number of boxes (1000)\n",
    "        self.F = F  # Features per box (4)\n",
    "        \n",
    "        # Box feature processor\n",
    "        self.box_encoder = nn.Sequential(\n",
    "            nn.Linear(F, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Algorithm-level processor\n",
    "        self.algorithm_processor = nn.Sequential(\n",
    "            nn.Linear(128 * K, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Final score predictor\n",
    "        self.score_predictor = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, M, K, F)\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Process all algorithms in parallel\n",
    "        # Reshape to (batch_size*M, K, F)\n",
    "        x = x.reshape(-1, self.K, self.F)\n",
    "        \n",
    "        # Process each box: (batch_size*M*K, F) -> (batch_size*M*K, 128)\n",
    "        encoded_boxes = self.box_encoder(x.reshape(-1, self.F))\n",
    "        \n",
    "        # Reshape back to (batch_size*M, K*128)\n",
    "        encoded_boxes = encoded_boxes.reshape(batch_size * self.M, -1)\n",
    "        \n",
    "        # Process all boxes for each algorithm: (batch_size*M, 128)\n",
    "        algo_features = self.algorithm_processor(encoded_boxes)\n",
    "        \n",
    "        # Predict scores: (batch_size*M, 1)\n",
    "        scores = self.score_predictor(algo_features)\n",
    "        \n",
    "        # Reshape to final output: (batch_size, M)\n",
    "        return scores.reshape(batch_size, self.M)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BoxPredictor(M=9, K=1000, F=4).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Training Loop with gradient clipping\n",
    "def train_model(model, train_loader, test_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                test_loss += criterion(outputs, y_batch).item() * X_batch.size(0)\n",
    "        \n",
    "        # Print statistics\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        test_loss = test_loss / len(test_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, test_loader, epochs=20)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"box_predictor_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef38499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to random_50_16_merged_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configuration\n",
    "class_labels = [\n",
    "    \"initial\", \"SCALE\", \"PFS\", \"PFS'\", \"FTA\",\n",
    "    \"VPSC\", \"PRISM\", \"GTREE\", \"RWordle-L\"\n",
    "]\n",
    "input_dir = \"C:/Users/Informatics/Documents/ML4Vis/Data/random_50_16/res\"\n",
    "output_file = \"random_50_16_merged_data.json\"\n",
    "\n",
    "# Step 1: Merge all JSON files into structured format\n",
    "def merge_json_files(input_dir, class_labels):\n",
    "    merged_data = []\n",
    "    \n",
    "    # Group files by base name (e.g., \"random_50_1\")\n",
    "    file_groups = defaultdict(dict)\n",
    "    \n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            # Parse base name and algorithm\n",
    "            if filename.startswith(\"output_Diamond.json\"):\n",
    "                base_name = filename.replace(\"output_Diamond.json\", \"\").strip(\"_\")\n",
    "                algorithm = \"initial\"\n",
    "            else:\n",
    "                parts = filename.replace(\"output_\", \"\").replace(\".json\", \"\").split(\"_\")\n",
    "                base_name = \"_\".join(parts[:-1])\n",
    "                algorithm = parts[-1]\n",
    "            \n",
    "            # Load JSON data\n",
    "            with open(os.path.join(input_dir, filename), 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Store in groups\n",
    "            if base_name not in file_groups:\n",
    "                file_groups[base_name] = {\"base_name\": base_name, \"boxes\": []}\n",
    "            \n",
    "            # Ensure boxes are ordered by class_labels\n",
    "            if algorithm in class_labels:\n",
    "                idx = class_labels.index(algorithm)\n",
    "                # Pad with empty lists if necessary\n",
    "                while len(file_groups[base_name][\"boxes\"]) <= idx:\n",
    "                    file_groups[base_name][\"boxes\"].append([])\n",
    "                file_groups[base_name][\"boxes\"][idx] = data[\"boxes\"]\n",
    "    \n",
    "    # Convert to list and ensure proper ordering\n",
    "    for base_name in sorted(file_groups.keys()):\n",
    "        entry = file_groups[base_name]\n",
    "        # Fill any missing algorithms with empty boxes\n",
    "        while len(entry[\"boxes\"]) < len(class_labels):\n",
    "            entry[\"boxes\"].append([])\n",
    "        merged_data.append(entry)\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "# Step 2: Save merged data\n",
    "merged_data = merge_json_files(input_dir, class_labels)\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(merged_data, f, indent=2)\n",
    "\n",
    "print(f\"Merged data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32990d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to algorithm_predictions.json\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Prepare for neural network prediction\n",
    "def prepare_for_prediction(merged_file, class_labels):\n",
    "    with open(merged_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    N = len(data)\n",
    "    M = len(class_labels)\n",
    "    K = 1000  # Maximum number of boxes to consider\n",
    "    F = 4     # Box features\n",
    "    \n",
    "    X_tensor = np.zeros((N, M, K, F), dtype=np.float32)\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        for j, boxes in enumerate(entry[\"boxes\"]):\n",
    "            # Take first K boxes if available\n",
    "            num_boxes = min(len(boxes), K)\n",
    "            if num_boxes > 0:\n",
    "                X_tensor[i, j, :num_boxes] = boxes[:num_boxes]\n",
    "    \n",
    "    return X_tensor\n",
    "\n",
    "# Load the trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BoxPredictor(M=len(class_labels), K=1000, F=4).to(device)\n",
    "model.load_state_dict(torch.load(\"box_predictor_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Step 4: Predict best algorithm\n",
    "def predict_best_algorithm(merged_file, model, class_labels):\n",
    "    X_tensor = prepare_for_prediction(merged_file, class_labels)\n",
    "    X_tensor = torch.tensor(X_tensor, dtype=torch.float32).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(len(X_tensor)):\n",
    "        scores = predictions[i].cpu().numpy()\n",
    "        best_idx = np.argmax(scores)\n",
    "        results.append({\n",
    "            \"base_name\": \"unix\",\n",
    "            \"predicted_scores\": {class_labels[j]: float(scores[j]) for j in range(len(class_labels))},\n",
    "            \"best_algorithm\": class_labels[best_idx],\n",
    "            \"best_score\": float(scores[best_idx])\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "output_file=\"unix_merged_data.json\"\n",
    "# Make predictions\n",
    "predictions = predict_best_algorithm(output_file, model, class_labels)\n",
    "\n",
    "# Save predictions\n",
    "with open(\"algorithm_predictionsunix.json\", 'w') as f:\n",
    "    json.dump(predictions, f, indent=2)\n",
    "\n",
    "print(\"Predictions saved to algorithm_predictions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e1f0455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Informatics\\AppData\\Local\\Temp\\ipykernel_7348\\1632551695.py:33: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = cm.get_cmap('tab10', len(class_labels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to box_visualization_random_50_16_row_with_axes.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "# ---------- Load Data ----------\n",
    "def load_json_file(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        content = f.read().strip()\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "            if isinstance(data, str):\n",
    "                data = json.loads(data)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading {filepath}: {e}\")\n",
    "\n",
    "# Load box data and predictions\n",
    "merged_entry = load_json_file(\"merged_data.json\")\n",
    "predictions = load_json_file(\"algorithm_predictions.json\")\n",
    "\n",
    "# Make prediction lookup by base_name\n",
    "prediction_dict = {\n",
    "    p[\"base_name\"]: p for p in predictions if isinstance(p, dict) and \"base_name\" in p\n",
    "}\n",
    "\n",
    "# ---------- Visualization Setup ----------\n",
    "class_labels = [\n",
    "    \"initial\", \"SCALE\", \"PFS\", \"PFS'\", \"FTA\",\n",
    "    \"VPSC\", \"PRISM\", \"GTREE\", \"RWordle-L\"\n",
    "]\n",
    "colors = cm.get_cmap('tab10', len(class_labels))\n",
    "algorithm_colors = {algo: to_rgba(colors(i)) for i, algo in enumerate(class_labels)}\n",
    "\n",
    "def plot_boxes(entry, prediction, figsize=(36, 5)):\n",
    "    base_name = entry[\"base_name\"]\n",
    "    best_algo = prediction[\"best_algorithm\"]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 9, figsize=figsize)\n",
    "    fig.suptitle(f\"Box Visualization - {base_name}\\nBest Algorithm: {best_algo} (Score: {prediction['best_score']:.3f})\",\n",
    "                 fontsize=16, y=1.15)\n",
    "\n",
    "    for i, (algo, ax) in enumerate(zip(class_labels, axes)):\n",
    "        boxes = entry[\"boxes\"][i] if i < len(entry[\"boxes\"]) else []\n",
    "\n",
    "        facecolor = list(algorithm_colors[algo])\n",
    "        facecolor[3] = 0.3  # transparency\n",
    "\n",
    "        valid_boxes = 0\n",
    "        all_x = []\n",
    "        all_y = []\n",
    "\n",
    "        for box in boxes:\n",
    "            if isinstance(box, list) and len(box) == 4:\n",
    "                try:\n",
    "                    x, y, w, h = [float(coord) for coord in box]\n",
    "                    all_x.extend([x, x + w])\n",
    "                    all_y.extend([y, y + h])\n",
    "\n",
    "                    rect = patches.Rectangle((x, y), w, h, linewidth=1,\n",
    "                                             edgecolor=algorithm_colors[algo],\n",
    "                                             facecolor=facecolor)\n",
    "                    ax.add_patch(rect)\n",
    "                    valid_boxes += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Invalid box in {base_name}/{algo}: {box} - {str(e)}\")\n",
    "\n",
    "        if valid_boxes > 0:\n",
    "            min_x, max_x = min(all_x), max(all_x)\n",
    "            min_y, max_y = min(all_y), max(all_y)\n",
    "            pad_x = (max_x - min_x) * 0.05\n",
    "            pad_y = (max_y - min_y) * 0.05\n",
    "            ax.set_xlim(min_x - pad_x, max_x + pad_x)\n",
    "            ax.set_ylim(min_y - pad_y, max_y + pad_y)\n",
    "        else:\n",
    "            ax.set_xlim(0, 100)\n",
    "            ax.set_ylim(0, 100)\n",
    "\n",
    "        ax.set_title(f\"{algo}\\nScore: {prediction.get('predicted_scores', {}).get(algo, 0):.2f}\\nBoxes: {valid_boxes}\",\n",
    "                     fontsize=9)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"y\")\n",
    "        ax.grid(True)\n",
    "\n",
    "        if algo == best_algo:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('red')\n",
    "                spine.set_linewidth(3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ---------- Main Execution ----------\n",
    "base_name = merged_entry.get(\"base_name\", \"unknown\")\n",
    "prediction = prediction_dict.get(base_name)\n",
    "\n",
    "if prediction is None:\n",
    "    print(f\"No prediction found for base_name: {base_name}\")\n",
    "else:\n",
    "    fig = plot_boxes(merged_entry, prediction)\n",
    "    output_file = f\"box_visualization_{base_name}_row_with_axes.png\"\n",
    "    fig.savefig(output_file, bbox_inches=\"tight\", dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b3e1bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Informatics\\AppData\\Local\\Temp\\ipykernel_14568\\2580554968.py:33: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = cm.get_cmap('tab10', len(class_labels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to results/b124_row_with_axes.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "# ---------- Load Data ----------\n",
    "def load_json_file(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        content = f.read().strip()\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "            if isinstance(data, str):\n",
    "                data = json.loads(data)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading {filepath}: {e}\")\n",
    "\n",
    "# Load box data and predictions\n",
    "merged_entries = load_json_file(\"b124_merged_data.json\")  # Now plural since it's a list\n",
    "predictions = load_json_file(\"algorithm_predictionsb124.json\")\n",
    "\n",
    "# Make prediction lookup by base_name\n",
    "prediction_dict = {\n",
    "    p[\"base_name\"]: p for p in predictions if isinstance(p, dict) and \"base_name\" in p\n",
    "}\n",
    "\n",
    "# ---------- Visualization Setup ----------\n",
    "class_labels = [\n",
    "    \"initial\", \"SCALE\", \"PFS\", \"PFS'\", \"FTA\",\n",
    "    \"VPSC\", \"PRISM\", \"GTREE\", \"RWordle-L\"\n",
    "]\n",
    "colors = cm.get_cmap('tab10', len(class_labels))\n",
    "algorithm_colors = {algo: to_rgba(colors(i)) for i, algo in enumerate(class_labels)}\n",
    "\n",
    "def plot_boxes(entry, prediction, figsize=(36, 5)):\n",
    "    base_name = entry[\"base_name\"]\n",
    "    best_algo = prediction[\"best_algorithm\"]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 9, figsize=figsize)\n",
    "    fig.suptitle(f\"Box Visualization - {base_name}\\nBest Algorithm: {best_algo}\",\n",
    "                fontsize=16, y=1.15)\n",
    "\n",
    "    for i, (algo, ax) in enumerate(zip(class_labels, axes)):\n",
    "        boxes = entry[\"boxes\"][i] if i < len(entry[\"boxes\"]) else []\n",
    "\n",
    "        facecolor = list(algorithm_colors[algo])\n",
    "        facecolor[3] = 0.3  # transparency\n",
    "\n",
    "        valid_boxes = 0\n",
    "        all_x = []\n",
    "        all_y = []\n",
    "\n",
    "        for box in boxes:\n",
    "            if isinstance(box, list) and len(box) == 4:\n",
    "                try:\n",
    "                    x, y, w, h = [float(coord) for coord in box]\n",
    "                    all_x.extend([x, x + w])\n",
    "                    all_y.extend([y, y + h])\n",
    "\n",
    "                    rect = patches.Rectangle((x, y), w, h, linewidth=1,\n",
    "                                           edgecolor=algorithm_colors[algo],\n",
    "                                           facecolor=facecolor)\n",
    "                    ax.add_patch(rect)\n",
    "                    valid_boxes += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Invalid box in {base_name}/{algo}: {box} - {str(e)}\")\n",
    "\n",
    "        if valid_boxes > 0:\n",
    "            min_x, max_x = min(all_x), max(all_x)\n",
    "            min_y, max_y = min(all_y), max(all_y)\n",
    "            pad_x = (max_x - min_x) * 0.05\n",
    "            pad_y = (max_y - min_y) * 0.05\n",
    "            ax.set_xlim(min_x - pad_x, max_x + pad_x)\n",
    "            ax.set_ylim(min_y - pad_y, max_y + pad_y)\n",
    "        else:\n",
    "            ax.set_xlim(0, 100)\n",
    "            ax.set_ylim(0, 100)\n",
    "\n",
    "        ax.set_title(f\"{algo}\\nScore: {prediction.get('predicted_scores', {}).get(algo, 0):.2f}\\nBoxes: {valid_boxes}\",\n",
    "                    fontsize=9)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"y\")\n",
    "        ax.grid(True)\n",
    "\n",
    "        if algo == best_algo:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('red')\n",
    "                spine.set_linewidth(3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ---------- Main Execution ----------\n",
    "# Process each entry in merged_entries (which is a list)\n",
    "for merged_entry in merged_entries:\n",
    "    base_name = merged_entry.get(\"base_name\", \"unknown\")\n",
    "    prediction = prediction_dict.get(base_name)\n",
    "\n",
    "    if prediction is None:\n",
    "        print(f\"No prediction found for base_name: {base_name}\")\n",
    "    else:\n",
    "        fig = plot_boxes(merged_entry, prediction)\n",
    "        output_file = f\"results/{base_name}_row_with_axes.png\"\n",
    "        fig.savefig(output_file, bbox_inches=\"tight\", dpi=150)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "688b8660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Informatics\\AppData\\Local\\Temp\\ipykernel_14568\\271642520.py:169: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created normalized matrix visualization: results/algorithm_matrix_normalized.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Setup\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.facecolor': 'white',\n",
    "    'figure.facecolor': 'white',\n",
    "    'savefig.facecolor': 'white'\n",
    "})\n",
    "\n",
    "# Dataset and algorithm configuration\n",
    "DATASETS = [\n",
    "    {\"name\": \"b124\", \"data_file\": \"b124_merged_data.json\", \"pred_file\": \"algorithm_predictionsb124.json\"},\n",
    "    {\"name\": \"rowe\", \"data_file\": \"rowe_merged_data.json\", \"pred_file\": \"algorithm_predictionsR.json\"},\n",
    "    {\"name\": \"random_50_16\", \"data_file\": \"random_50_16_merged_data.json\", \"pred_file\": \"random_50_16algorithm_predictions.json\"}\n",
    "]\n",
    "\n",
    "ALGORITHMS = [\"initial\", \"SCALE\", \"PFS\", \"PFS'\", \"FTA\", \"VPSC\", \"PRISM\", \"GTREE\", \"RWordle-L\"]\n",
    "COLORS = plt.cm.tab10(np.linspace(0, 1, len(ALGORITHMS)))\n",
    "\n",
    "def load_json_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load and prepare data\n",
    "matrix_data = []\n",
    "for dataset in DATASETS:\n",
    "    entries = load_json_file(dataset[\"data_file\"])\n",
    "    preds = load_json_file(dataset[\"pred_file\"])\n",
    "    \n",
    "    if entries and preds:\n",
    "        entries = entries if isinstance(entries, list) else [entries]\n",
    "        preds = preds if isinstance(preds, list) else [preds]\n",
    "        \n",
    "        pred_map = {p[\"base_name\"].lower(): p for p in preds if isinstance(p, dict)}\n",
    "        for entry in entries:\n",
    "            base_name = entry.get(\"base_name\", \"\").lower()\n",
    "            if base_name in pred_map:\n",
    "                matrix_data.append({\n",
    "                    \"name\": dataset[\"name\"],\n",
    "                    \"entry\": entry,\n",
    "                    \"prediction\": pred_map[base_name]\n",
    "                })\n",
    "\n",
    "if not matrix_data:\n",
    "    print(\"No valid data to plot!\")\n",
    "    exit()\n",
    "\n",
    "# Calculate maximum dimensions across all algorithms\n",
    "max_width = 0\n",
    "max_height = 0\n",
    "for data in matrix_data:\n",
    "    for boxes in data[\"entry\"][\"boxes\"]:\n",
    "        for box in boxes:\n",
    "            if isinstance(box, list) and len(box) == 4:\n",
    "                max_width = max(max_width, box[2])\n",
    "                max_height = max(max_height, box[3])\n",
    "\n",
    "# Create figure with grid layout\n",
    "fig = plt.figure(figsize=(20, 3 * len(matrix_data)))\n",
    "grid = plt.GridSpec(\n",
    "    len(matrix_data) + 1,\n",
    "    len(ALGORITHMS) + 1,\n",
    "    wspace=0.1,\n",
    "    hspace=0.2,\n",
    "    width_ratios=[0.5] + [1]*len(ALGORITHMS),\n",
    "    height_ratios=[0.3] + [1]*len(matrix_data)\n",
    ")\n",
    "\n",
    "# Create header row\n",
    "for col_idx, (algo, color) in enumerate(zip(ALGORITHMS, COLORS), 1):\n",
    "    ax = plt.subplot(grid[0, col_idx])\n",
    "    ax.set_facecolor('white')\n",
    "    ax.text(0.5, 0.5, algo, \n",
    "            ha='center', va='center',\n",
    "            fontsize=12, fontweight='bold',\n",
    "            bbox=dict(facecolor=color, alpha=0.3))\n",
    "    ax.axis('off')\n",
    "\n",
    "# Create row labels\n",
    "for row_idx, data in enumerate(matrix_data, 1):\n",
    "    ax = plt.subplot(grid[row_idx, 0])\n",
    "    ax.set_facecolor('white')\n",
    "    ax.text(0.5, 0.5, data[\"name\"],\n",
    "            ha='center', va='center',\n",
    "            fontsize=12, fontweight='bold',\n",
    "            rotation=90)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Plot data cells with consistent scaling\n",
    "for row_idx, data in enumerate(matrix_data, 1):\n",
    "    entry = data[\"entry\"]\n",
    "    pred = data[\"prediction\"]\n",
    "    \n",
    "    for col_idx, (algo, color) in enumerate(zip(ALGORITHMS, COLORS), 1):\n",
    "        ax = plt.subplot(grid[row_idx, col_idx])\n",
    "        ax.set_facecolor('white')\n",
    "        boxes = entry[\"boxes\"][col_idx-1] if (col_idx-1) < len(entry[\"boxes\"]) else []\n",
    "        \n",
    "        # Calculate cell-specific limits\n",
    "        x_min = y_min = float('inf')\n",
    "        x_max = y_max = -float('inf')\n",
    "        \n",
    "        for box in boxes:\n",
    "            if isinstance(box, list) and len(box) == 4:\n",
    "                x, y, w, h = box\n",
    "                x_min = min(x_min, x)\n",
    "                y_min = min(y_min, y)\n",
    "                x_max = max(x_max, x + w)\n",
    "                y_max = max(y_max, y + h)\n",
    "        \n",
    "        # Apply padding if boxes exist, else use defaults\n",
    "        if x_max > -float('inf'):\n",
    "            pad_x = (x_max - x_min) * 0.1\n",
    "            pad_y = (y_max - y_min) * 0.1\n",
    "            xlim = [x_min - pad_x, x_max + pad_x]\n",
    "            ylim = [y_min - pad_y, y_max + pad_y]\n",
    "        else:\n",
    "            xlim = [0, max_width * 1.2]\n",
    "            ylim = [0, max_height * 1.2]\n",
    "        \n",
    "        # Plot boxes with normalized sizes\n",
    "        for box in boxes:\n",
    "            if isinstance(box, list) and len(box) == 4:\n",
    "                x, y, w, h = box\n",
    "                # Normalize position while maintaining size\n",
    "                norm_x = x_min + (x - x_min) * (xlim[1] - xlim[0]) / (x_max - x_min) if x_max > x_min else x\n",
    "                norm_y = y_min + (y - y_min) * (ylim[1] - ylim[0]) / (y_max - y_min) if y_max > y_min else y\n",
    "                \n",
    "                rect = patches.Rectangle(\n",
    "                    (norm_x, norm_y), w, h,\n",
    "                    linewidth=0.8,\n",
    "                    edgecolor=color,\n",
    "                    facecolor=color,\n",
    "                    alpha=0.6\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "        \n",
    "        # Highlight best algorithm\n",
    "        if algo == pred[\"best_algorithm\"]:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('red')\n",
    "                spine.set_linewidth(3)\n",
    "        \n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.grid(True, linestyle=':', alpha=0.3)\n",
    "        \n",
    "        # Add max dimensions text\n",
    "        if boxes:\n",
    "            ax.text(0.95, 0.95, \n",
    "                   f\"Max X: {x_max:.1f}\\nMax Y: {y_max:.1f}\",\n",
    "                   ha='right', va='top',\n",
    "                   transform=ax.transAxes,\n",
    "                   bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "output_file = \"results/algorithm_matrix_normalized.png\"\n",
    "fig.savefig(output_file, bbox_inches=\"tight\", dpi=150)\n",
    "plt.close(fig)\n",
    "print(f\"Created normalized matrix visualization: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c45d04a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Informatics\\AppData\\Local\\Temp\\ipykernel_14568\\777945231.py:160: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created matrix visualization with axis values: results/algorithm_matrix_with_axis_values.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Setup\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 10,\n",
    "    'axes.facecolor': 'white',\n",
    "    'figure.facecolor': 'white',\n",
    "    'savefig.facecolor': 'white'\n",
    "})\n",
    "\n",
    "# Configuration\n",
    "DATASETS = [\n",
    "    {\"name\": \"rowe\", \"data_file\": \"rowe_merged_data.json\", \"pred_file\": \"algorithm_predictionsR.json\"},\n",
    "    {\"name\": \"random_50_16\", \"data_file\": \"random_50_16_merged_data.json\", \"pred_file\": \"random_50_16algorithm_predictions.json\"},\n",
    "    {\"name\": \"b124\", \"data_file\": \"b124_merged_data.json\", \"pred_file\": \"algorithm_predictionsb124.json\"}\n",
    "    \n",
    "]\n",
    "\n",
    "ALGORITHMS = [\"initial\", \"SCALE\", \"PFS\", \"PFS'\", \"FTA\", \"VPSC\", \"PRISM\", \"GTREE\", \"RWordle-L\"]\n",
    "COLORS = plt.cm.tab10(np.linspace(0, 1, len(ALGORITHMS)))\n",
    "\n",
    "def load_json_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load data\n",
    "matrix_data = []\n",
    "for dataset in DATASETS:\n",
    "    entries = load_json_file(dataset[\"data_file\"])\n",
    "    preds = load_json_file(dataset[\"pred_file\"])\n",
    "    \n",
    "    if entries and preds:\n",
    "        entries = entries if isinstance(entries, list) else [entries]\n",
    "        preds = preds if isinstance(preds, list) else [preds]\n",
    "        \n",
    "        pred_map = {p[\"base_name\"].lower(): p for p in preds if isinstance(p, dict)}\n",
    "        for entry in entries:\n",
    "            base_name = entry.get(\"base_name\", \"\").lower()\n",
    "            if base_name in pred_map:\n",
    "                matrix_data.append({\n",
    "                    \"name\": dataset[\"name\"],\n",
    "                    \"entry\": entry,\n",
    "                    \"prediction\": pred_map[base_name]\n",
    "                })\n",
    "\n",
    "if not matrix_data:\n",
    "    print(\"No valid data to plot!\")\n",
    "    exit()\n",
    "\n",
    "# Create figure with additional row for axis values\n",
    "fig = plt.figure(figsize=(22, 3.5 * len(matrix_data)))\n",
    "grid = plt.GridSpec(\n",
    "    len(matrix_data) * 2 + 1,  # Data rows + axis rows + header\n",
    "    len(ALGORITHMS) + 1,\n",
    "    wspace=0.1,\n",
    "    hspace=0.05,\n",
    "    width_ratios=[0.5] + [1]*len(ALGORITHMS),\n",
    "    height_ratios=[0.3] + [1, 0.2]*len(matrix_data)  # Alternating data and axis rows\n",
    ")\n",
    "\n",
    "# Header row\n",
    "for col_idx, (algo, color) in enumerate(zip(ALGORITHMS, COLORS), 1):\n",
    "    ax = plt.subplot(grid[0, col_idx])\n",
    "    ax.set_facecolor('white')\n",
    "    ax.text(0.5, 0.5, algo, \n",
    "            ha='center', va='center',\n",
    "            fontsize=12, fontweight='bold',\n",
    "            bbox=dict(facecolor=color, alpha=0.3))\n",
    "    ax.axis('off')\n",
    "\n",
    "# Data and axis rows\n",
    "for row_idx, data in enumerate(matrix_data):\n",
    "    entry = data[\"entry\"]\n",
    "    pred = data[\"prediction\"]\n",
    "    \n",
    "    # Dataset label\n",
    "    label_ax = plt.subplot(grid[row_idx*2+1, 0])\n",
    "    label_ax.set_facecolor('white')\n",
    "    label_ax.text(0.5, 0.5, data[\"name\"],\n",
    "                 ha='center', va='center',\n",
    "                 fontsize=12, fontweight='bold',\n",
    "                 rotation=90)\n",
    "    label_ax.axis('off')\n",
    "    \n",
    "    # Plot data cells\n",
    "    for col_idx, (algo, color) in enumerate(zip(ALGORITHMS, COLORS), 1):\n",
    "        # Main plot area\n",
    "        ax = plt.subplot(grid[row_idx*2+1, col_idx])\n",
    "        ax.set_facecolor('white')\n",
    "        boxes = entry[\"boxes\"][col_idx-1] if (col_idx-1) < len(entry[\"boxes\"]) else []\n",
    "        \n",
    "        # Calculate limits\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        for box in boxes:\n",
    "            if isinstance(box, list) and len(box) == 4:\n",
    "                x, y, w, h = box\n",
    "                x_vals.extend([x, x+w])\n",
    "                y_vals.extend([y, y+h])\n",
    "        \n",
    "        if x_vals:\n",
    "            x_pad = (max(x_vals) - min(x_vals)) * 0.1\n",
    "            y_pad = (max(y_vals) - min(y_vals)) * 0.1\n",
    "            xlim = [min(x_vals)-x_pad, max(x_vals)+x_pad]\n",
    "            ylim = [min(y_vals)-y_pad, max(y_vals)+y_pad]\n",
    "        else:\n",
    "            xlim = [0, 100]\n",
    "            ylim = [0, 100]\n",
    "        \n",
    "        # Plot boxes\n",
    "        for box in boxes:\n",
    "            if isinstance(box, list) and len(box) == 4:\n",
    "                x, y, w, h = box\n",
    "                rect = patches.Rectangle(\n",
    "                    (x, y), w, h,\n",
    "                    linewidth=0.8,\n",
    "                    edgecolor=color,\n",
    "                    facecolor=color,\n",
    "                    alpha=0.6\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "        \n",
    "        # Highlight best algorithm\n",
    "        if algo == pred[\"best_algorithm\"]:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('red')\n",
    "                spine.set_linewidth(3)\n",
    "        \n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.grid(True, linestyle=':', alpha=0.3)\n",
    "        \n",
    "        # Axis values display\n",
    "        if row_idx < len(matrix_data):  # Only create once per row\n",
    "            axis_ax = plt.subplot(grid[row_idx*2+2, col_idx])\n",
    "            axis_ax.set_facecolor('white')\n",
    "            \n",
    "            if x_vals:\n",
    "                axis_ax.text(0.5, 0.7, f\"X: {min(x_vals):.1f}-{max(x_vals):.1f}\", \n",
    "                            ha='center', va='center', fontsize=9)\n",
    "                axis_ax.text(0.5, 0.3, f\"Y: {min(y_vals):.1f}-{max(y_vals):.1f}\", \n",
    "                            ha='center', va='center', fontsize=9)\n",
    "            else:\n",
    "                axis_ax.text(0.5, 0.5, \"No data\", ha='center', va='center', fontsize=9)\n",
    "            \n",
    "            axis_ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "output_file = \"results/algorithm_matrix_with_axis_values.png\"\n",
    "fig.savefig(output_file, bbox_inches=\"tight\", dpi=150)\n",
    "plt.close(fig)\n",
    "print(f\"Created matrix visualization with axis values: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
